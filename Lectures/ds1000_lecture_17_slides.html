<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Classification</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Bisbee" />
    <script src="libs/header-attrs-2.23/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/lexis.css" type="text/css" />
    <link rel="stylesheet" href="css/lexis-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Classification
]
.subtitle[
## Part 3
]
.author[
### Prof. Bisbee
]
.institute[
### Vanderbilt University
]
.date[
### Slides Updated: 2024-03-16
]

---


&lt;style type="text/css"&gt;
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
&lt;/style&gt;



# Agenda

1. Recap of regression and classification

2. Introducing (some) machine learning algorithms

---

# What is regression?

--

- Conditional means for continuous data

--


&lt;center&gt;&lt;img src="figs/condmean_reg.png" width = 45%&gt;&lt;/center&gt;

---

# Regression

--

- Calculating a **line** that minimizes mistakes *for every observation*

--

  - NB: could be a curvey line! For now, just assume straight
  
--

- Recall from geometry how to graph a straight line

--

- `\(Y = a + bX\)`

  - `\(a\)`: the "intercept" (where the line intercepts the y-axis)
  - `\(b\)`: the "slope" (how much `\(Y\)` changes for each increase in `\(X\)`)

--

- (Data scientists use `\(\alpha\)` and `\(\beta\)` instead of `\(a\)` and `\(b\)` b/c nerds)

--

- Regression analysis simply chooses the best line

--

  - "Best"?

--

  - The line that minimizes the mistakes (the **line of best fit**)

---

# Visual Intuition

&lt;center&gt;&lt;img src="./figs/raw.png" width = 70%&gt;&lt;/center&gt;


---

# Visual Intuition

&lt;center&gt;&lt;img src="./figs/regression-line.gif" width = 70%&gt;&lt;/center&gt;

---

# Two Camps Revisited

--

- Regression is great for **theory testing**

--

  - Results tell us something **meaningful** about our theory
  
--

- But if all we care about is **prediction**...?

--

  - Want to test every possible predictor (and combinations)
  
  - Don't care about **relationships**
  
  - Just care about **accuracy**
  
--

- Algorithms can save us time!

--

  - Random Forests
  
  - LASSO
  
---

# Random Forests

- Identify the best "partition" (split) that divides the data

--

&lt;center&gt;&lt;img src="./figs/rfdemo.gif" width = 70%&gt;&lt;/center&gt;

--

- In `R`: `ranger`

--

  - `formula = Y ~ .`

---

# Random Forests


```r
require(tidyverse)
require(scales)
require(tidymodels)
fn &lt;- read_rds('C:/Users/bisbeejh/Dropbox/2024_spring/DS1000_S2024/data/fn_cleaned_final.rds')
```


---

# Research Question

- What predicts whether you win at Fortnite?


```r
form.perf &lt;- 'won ~ hits + assists + accuracy + head_shots + damage_to_players'

form.games &lt;- 'won ~ eliminations + revives + distance_traveled + materials_gathered'

form.context &lt;- 'won ~ mental_state + startTime + gameIdSession'

form.full &lt;- 'won ~ hits + assists + accuracy + head_shots + damage_to_players + eliminations + revives + distance_traveled + materials_gathered + mental_state + startTime + gameIdSession'
```

---

# Comparing models


```r
m.perf &lt;- lm(as.formula(form.perf),fn)
summary(m.perf)
```

```
## 
## Call:
## lm(formula = as.formula(form.perf), data = fn)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.7905 -0.2756 -0.1563  0.3429  1.0078 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)        8.788e-02  3.768e-02   2.332 0.019893
## hits               6.962e-04  1.001e-03   0.695 0.487053
## assists            3.445e-02  1.020e-02   3.377 0.000764
## accuracy          -4.164e-01  1.081e-01  -3.850 0.000126
## head_shots        -4.808e-03  3.149e-03  -1.527 0.127057
## damage_to_players  4.728e-04  5.713e-05   8.275 4.31e-16
##                      
## (Intercept)       *  
## hits                 
## assists           ***
## accuracy          ***
## head_shots           
## damage_to_players ***
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4191 on 951 degrees of freedom
## Multiple R-squared:  0.1752,	Adjusted R-squared:  0.1708 
## F-statistic:  40.4 on 5 and 951 DF,  p-value: &lt; 2.2e-16
```

---

# Comparing models


```r
m.games &lt;- lm(as.formula(form.games),fn)
summary(m.games)
```

```
## 
## Call:
## lm(formula = as.formula(form.games), data = fn)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.0107 -0.2320 -0.1275  0.2028  0.9583 
## 
## Coefficients:
##                      Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)         4.171e-02  2.210e-02   1.888 0.059397
## eliminations        1.151e-02  9.765e-03   1.178 0.238921
## revives             6.993e-02  1.809e-02   3.865 0.000119
## distance_traveled   1.805e-04  1.755e-05  10.287  &lt; 2e-16
## materials_gathered -2.550e-06  3.515e-05  -0.073 0.942186
##                       
## (Intercept)        .  
## eliminations          
## revives            ***
## distance_traveled  ***
## materials_gathered    
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.398 on 952 degrees of freedom
## Multiple R-squared:  0.2554,	Adjusted R-squared:  0.2523 
## F-statistic: 81.64 on 4 and 952 DF,  p-value: &lt; 2.2e-16
```

---

# Comparing models


```r
m.context &lt;- lm(as.formula(form.context),fn)
summary(m.context)
```

```
## 
## Call:
## lm(formula = as.formula(form.context), data = fn)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -0.4698 -0.3258 -0.2340  0.5857  0.8553 
## 
## Coefficients:
##                     Estimate Std. Error t value Pr(&gt;|t|)
## (Intercept)        9.027e+01  2.987e+01   3.022  0.00258
## mental_statesober  1.368e-01  2.933e-02   4.663 3.56e-06
## startTime         -5.672e-08  1.881e-08  -3.015  0.00264
## gameIdSession      1.460e-03  1.463e-03   0.998  0.31863
##                      
## (Intercept)       ** 
## mental_statesober ***
## startTime         ** 
## gameIdSession        
## ---
## Signif. codes:  
## 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4534 on 953 degrees of freedom
## Multiple R-squared:  0.03282,	Adjusted R-squared:  0.02978 
## F-statistic: 10.78 on 3 and 953 DF,  p-value: 5.706e-07
```

---

# Evaluate Model Fit


```r
cvRes &lt;- NULL
for(i in 1:100) {
  inds &lt;- sample(1:nrow(fn),size = round(nrow(fn)*.8),replace = F)
  train &lt;- fn %&gt;% slice(inds)
  test &lt;- fn %&gt;% slice(-inds)
  
  # Train
  mTmp.perf &lt;- lm(as.formula(form.perf),train)
  mTmp.games &lt;- lm(as.formula(form.games),train)
  mTmp.context &lt;- lm(as.formula(form.context),train)
  
  # Test
  toEval &lt;- test %&gt;%
    mutate(prob.p = predict(mTmp.perf,newdata = test),
           prob.g = predict(mTmp.games,newdata = test),
           prob.c = predict(mTmp.context,newdata = test),
           truth = factor(won,levels = c('1','0'))) 
  
  auc.p &lt;- roc_auc(toEval,truth,prob.p) %&gt;%
    mutate(model = 'performance')
  
  auc.g &lt;- roc_auc(toEval,truth,prob.g) %&gt;%
    mutate(model = 'games')
  
  auc.c &lt;- roc_auc(toEval,truth,prob.c) %&gt;%
    mutate(model = 'context')
    
  cvRes &lt;- cvRes %&gt;%
    bind_rows(auc.p) %&gt;%
    bind_rows(auc.g) %&gt;%
    bind_rows(auc.c) %&gt;%
    mutate(cvInd = i)
}
```

---

# Evaluate Model Fit


```r
cvRes %&gt;%
  ggplot(aes(x = .estimate,y = model)) + 
  geom_boxplot() + labs(x = 'AUC',y = 'Specification')
```

&lt;img src="ds1000_lecture_17_slides_files/figure-html/unnamed-chunk-9-1.png" style="display: block; margin: auto;" /&gt;

---

# Random Forests


```r
require(ranger) # Fast random forests package
```

```
## Warning: package 'ranger' was built under R version 4.3.3
```

```r
rf.f &lt;- ranger(formula = as.formula(form.full),data = fn)

toEval &lt;- fn %&gt;%
  mutate(prob_won = rf.f$predictions) %&gt;%
  mutate(truth = factor(won,levels = c('1','0')))

roc_auc(toEval,truth,prob_won)
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.838
```

---

# Random Forest Comparison


```r
cvRes &lt;- NULL
for(i in 1:100) {
  inds &lt;- sample(1:nrow(fn),size = round(nrow(fn)*.8),replace = F)
  train &lt;- fn %&gt;% slice(inds)
  test &lt;- fn %&gt;% slice(-inds)
  
  # Train
  mLM.f &lt;- lm(as.formula(form.full),train)
  mRF.f &lt;- ranger(as.formula(form.full),train)
  
  # Test
  # NEED TO RUN PREDICTION ON RF FIRST
  tmpPred &lt;- predict(mRF.f,test)
  
  toEval &lt;- test %&gt;%
    mutate(prob.lm = predict(mLM.f,newdata = test),
           prob.rf = tmpPred$predictions,
           truth = factor(won,levels = c('1','0')))
  
  auc.lm &lt;- roc_auc(toEval,truth,prob.lm) %&gt;%
    mutate(model = 'linear')
  
  auc.rf &lt;- roc_auc(toEval,truth,prob.rf) %&gt;%
    mutate(model = 'random forest')

    cvRes &lt;- cvRes %&gt;%
    bind_rows(auc.lm) %&gt;%
    bind_rows(auc.rf) %&gt;%
    mutate(cvInd = i)
}
```

---

# Random Forest Comparison


```r
cvRes %&gt;%
  ggplot(aes(x = .estimate,y = model)) + 
  geom_boxplot() + labs(x = 'AUC',y = 'Algorithm')
```

&lt;img src="ds1000_lecture_17_slides_files/figure-html/unnamed-chunk-12-1.png" style="display: block; margin: auto;" /&gt;

---

# What matters most?

- Random Forests are particularly suitable for investigating **variable importance**

--

  - I.e., which `\(X\)` predictors are most helpful?
  
--

- A few options, but we rely on **permutation tests**

--

  - Idea: run the best model you have, then re-run it after "permuting" one of the variables
  
  - "Permute" means randomly reshuffle...breaks relationship
  
  - How much **worse** is the model when you break a variable?
  
---

# Variable Importance

- In `ranger()`, use `importance = "permutation"`


```r
rf.full &lt;- ranger(formula = as.formula(form.full),data = fn %&gt;%
                    mutate(mental_state = ifelse(mental_state == 'sober',1,0)),importance = 'permutation')

rf.full$variable.importance
```

```
##               hits            assists           accuracy 
##        0.013744542        0.003357181        0.004465332 
##         head_shots  damage_to_players       eliminations 
##        0.006363476        0.032384850        0.010595106 
##            revives  distance_traveled materials_gathered 
##        0.004715412        0.070833478        0.025052451 
##       mental_state          startTime      gameIdSession 
##        0.003392765        0.002135140        0.026763760
```

---

# Variable Importance

.small[

```r
toplot &lt;- data.frame(vimp = rf.full$variable.importance,
                     vars = names(rf.full$variable.importance))

toplot %&gt;%
  ggplot(aes(x = vimp,y = reorder(vars,vimp))) + 
  geom_bar(stat = 'identity') + labs(x = 'VIMP',y = 'Predictor')
```

&lt;img src="ds1000_lecture_17_slides_files/figure-html/unnamed-chunk-14-1.png" style="display: block; margin: auto;" /&gt;
]


---

# LASSO

--

- "Least Absolute Shrinkage and Selection Operator"

--

- Concept: Make it hard for predictors to matter

--

  - Practice: `\(\lambda\)` penalizes how many variables you can include
  
  - `\(\sum_{i = 1}^n (y_i - \sum_j x_{ij}\beta_j)^2 + \lambda \sum_{j=1}^p |\beta_j|\)`
  
  - Minimize the errors, but penalize for each additional predictor
  
  - You *could* kitchen-sink a regression and get super low errors
  
  - LASSO penalizes you from throwing everything into the kitchen sink

--

- In `R`, need to install a new package! `install.packages('glmnet')`


```r
require(glmnet)
```

```
## Warning: package 'glmnet' was built under R version 4.3.2
```

---

# LASSO

- Function doesn't use formulas

--

- Give it the raw data instead, divided into `Y` (outcome) and `X` (predictors)

--


```r
rhsVars &lt;- str_split(gsub('won ~ ','',form.full),' \\+ ')[[1]]
fn &lt;- fn %&gt;%
  drop_na(all_of(rhsVars))
Y &lt;- fn$won
X &lt;- fn %&gt;% select(all_of(rhsVars)) %&gt;%
  mutate(mental_state = ifelse(mental_state == 'sober',1,0),
         startTime = as.numeric(startTime))
```


---

# LASSO

- Now estimate!


```r
lassFit &lt;- glmnet(x = as.matrix(X),
                  y = as.matrix(Y))
```

---

# LASSO


```r
plot(lassFit)
```

&lt;img src="ds1000_lecture_17_slides_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;

---

# Has its own CV!


```r
cv.lassFit &lt;- cv.glmnet(x = as.matrix(X),y = as.matrix(Y))

plot(cv.lassFit)
```

&lt;img src="ds1000_lecture_17_slides_files/figure-html/unnamed-chunk-19-1.png" style="display: block; margin: auto;" /&gt;

---

# Variable Importance


```r
best &lt;- cv.lassFit$glmnet.fit$beta[,cv.lassFit$index[2,]]
vimpLass &lt;- data.frame(vimp = best,
                       vars = names(best))
vimpLass %&gt;%
  ggplot(aes(x = vimp,y = reorder(vars,vimp))) + 
  geom_bar(stat = 'identity')
```

&lt;img src="ds1000_lecture_17_slides_files/figure-html/unnamed-chunk-20-1.png" style="display: block; margin: auto;" /&gt;

---

# Conclusion

- Lots of powerful tools out there!

- Make sure to take **more classes** on these topics!

--
  
- Go to Brightspace and take the **16th** quiz

--

- **Homework:**

  - Problem Set 9 (due 2024-03-29 by 11:59PM)
  
  - HW 17

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
