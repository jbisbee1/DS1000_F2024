<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Text, Tweets, and Sentiment</title>
    <meta charset="utf-8" />
    <meta name="author" content="Prof. Bisbee" />
    <script src="libs/header-attrs-2.22/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link rel="stylesheet" href="css/lexis.css" type="text/css" />
    <link rel="stylesheet" href="css/lexis-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Text, Tweets, and Sentiment
]
.subtitle[
## Part 3
]
.author[
### Prof. Bisbee
]
.institute[
### Vanderbilt University
]
.date[
### Slides Updated: 2024-08-10
]

---


&lt;style type="text/css"&gt;
.small .remark-code { /*Change made here*/
  font-size: 85% !important;
}
.tiny .remark-code { /*Change made here*/
  font-size: 50% !important;
}
&lt;/style&gt;



# Returning to Trump


```r
require(tidyverse)
tweet_words &lt;- read_rds(file="https://github.com/jbisbee1/DS1000_F2024/raw/main/data/Trump_tweet_words.Rds")
tweet_words &lt;- tweet_words %&gt;% mutate(PostPresident = Tweeting.date &gt; as.Date('2016-11-06'))
```

---

# Log-Odds

- **Odds**: Probability a word is used pre/post presidency
  
- **Log**: Useful for removing skew in data!
  
--

- Interactive code time!

---

# Odds Step 1


```r
(odds1 &lt;- tweet_words %&gt;%
  count(word, PostPresident) %&gt;%
  filter(sum(n) &gt;= 5) %&gt;%
  spread(PostPresident, n, fill = 0) %&gt;%
  ungroup() %&gt;%
  mutate(totFALSE = sum(`FALSE`),
         totTRUE = sum(`TRUE`)))
```

```
## # A tibble: 45,221 × 5
##    word      `FALSE` `TRUE` totFALSE totTRUE
##    &lt;chr&gt;       &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;
##  1 a               6     27   189217  257487
##  2 aa              1      2   189217  257487
##  3 aaa            11      1   189217  257487
##  4 aamp            1      0   189217  257487
##  5 aand            0      1   189217  257487
##  6 aaron           2      1   189217  257487
##  7 ab              1      2   189217  257487
##  8 abaco           0      1   189217  257487
##  9 abandon         6      8   189217  257487
## 10 abandoned      13     11   189217  257487
## # ℹ 45,211 more rows
```

---

# Odds Step 2


```r
(odds2 &lt;- odds1 %&gt;%
  mutate(propFALSE = (`FALSE` + 1) / (totFALSE + 1),
         propTRUE = (`TRUE` + 1) / (totTRUE + 1)))
```

```
## # A tibble: 45,221 × 7
##    word   `FALSE` `TRUE` totFALSE totTRUE propFALSE propTRUE
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 a            6     27   189217  257487   3.70e-5  1.09e-4
##  2 aa           1      2   189217  257487   1.06e-5  1.17e-5
##  3 aaa         11      1   189217  257487   6.34e-5  7.77e-6
##  4 aamp         1      0   189217  257487   1.06e-5  3.88e-6
##  5 aand         0      1   189217  257487   5.28e-6  7.77e-6
##  6 aaron        2      1   189217  257487   1.59e-5  7.77e-6
##  7 ab           1      2   189217  257487   1.06e-5  1.17e-5
##  8 abaco        0      1   189217  257487   5.28e-6  7.77e-6
##  9 aband…       6      8   189217  257487   3.70e-5  3.50e-5
## 10 aband…      13     11   189217  257487   7.40e-5  4.66e-5
## # ℹ 45,211 more rows
```

---

# Odds Step 3


```r
(odds3 &lt;- odds2 %&gt;%
  mutate(odds = propTRUE / propFALSE))
```

```
## # A tibble: 45,221 × 8
##    word   `FALSE` `TRUE` totFALSE totTRUE propFALSE propTRUE
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 a            6     27   189217  257487   3.70e-5  1.09e-4
##  2 aa           1      2   189217  257487   1.06e-5  1.17e-5
##  3 aaa         11      1   189217  257487   6.34e-5  7.77e-6
##  4 aamp         1      0   189217  257487   1.06e-5  3.88e-6
##  5 aand         0      1   189217  257487   5.28e-6  7.77e-6
##  6 aaron        2      1   189217  257487   1.59e-5  7.77e-6
##  7 ab           1      2   189217  257487   1.06e-5  1.17e-5
##  8 abaco        0      1   189217  257487   5.28e-6  7.77e-6
##  9 aband…       6      8   189217  257487   3.70e-5  3.50e-5
## 10 aband…      13     11   189217  257487   7.40e-5  4.66e-5
## # ℹ 45,211 more rows
## # ℹ 1 more variable: odds &lt;dbl&gt;
```

---

# Why log?


```r
odds3 %&gt;%
  ggplot(aes(x = odds)) + 
  geom_histogram()
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-7-1.png" style="display: block; margin: auto;" /&gt;

---

# Why log?


```r
odds3 %&gt;%
  ggplot(aes(x = odds)) + 
  geom_histogram(bins = 15) + 
  scale_x_log10()
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-8-1.png" style="display: block; margin: auto;" /&gt;

---

# Odds Step 4


```r
(prepost_logodds &lt;- odds3 %&gt;%
  mutate(logodds = log(odds)))
```

```
## # A tibble: 45,221 × 9
##    word   `FALSE` `TRUE` totFALSE totTRUE propFALSE propTRUE
##    &lt;chr&gt;    &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
##  1 a            6     27   189217  257487   3.70e-5  1.09e-4
##  2 aa           1      2   189217  257487   1.06e-5  1.17e-5
##  3 aaa         11      1   189217  257487   6.34e-5  7.77e-6
##  4 aamp         1      0   189217  257487   1.06e-5  3.88e-6
##  5 aand         0      1   189217  257487   5.28e-6  7.77e-6
##  6 aaron        2      1   189217  257487   1.59e-5  7.77e-6
##  7 ab           1      2   189217  257487   1.06e-5  1.17e-5
##  8 abaco        0      1   189217  257487   5.28e-6  7.77e-6
##  9 aband…       6      8   189217  257487   3.70e-5  3.50e-5
## 10 aband…      13     11   189217  257487   7.40e-5  4.66e-5
## # ℹ 45,211 more rows
## # ℹ 2 more variables: odds &lt;dbl&gt;, logodds &lt;dbl&gt;
```

---

# Effect of becoming president


```r
p &lt;- prepost_logodds %&gt;%
  group_by(logodds &gt; 0) %&gt;%
  top_n(15, abs(logodds)) %&gt;%
  ungroup() %&gt;%
  mutate(word = reorder(word, logodds)) %&gt;%
  ggplot(aes(word, logodds, fill = logodds &lt; 0)) +
  geom_bar(stat = "identity") +
  coord_flip() +
  ylab("Post-President/Pre-President log ratio") +
  scale_fill_manual(name = "", labels = c("President", "Pre-President"),
                    values = c("red", "lightblue"))
```

---

# Effect of becoming president


```r
p
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-11-1.png" style="display: block; margin: auto;" /&gt;

---

# Meaning

- Thus far, everything is **topic**-related

--

  - How often he talks about things
  
--

- But what does he **mean** when he talks about Mueller?

--

  - We can probably guess
  
--

- But we want a more systematic method

--

  - **Sentiment**: the *feeling* behind words
  
---

# Meaning

- **Sentiment** analysis is based on **dictionaries**

--

  - Just like **stop words** from last week!
  
--

  - Prepared lists of words, but tagged according to **emotion**
  
--

- Good dictionary included in `tidytext` package


```r
require(tidytext) # Might need to install.packages('textdata')
# nrc &lt;- get_sentiments("nrc")
# If this doesn't work on your computer, just load it with read_rds()
nrc &lt;- read_rds('https://github.com/jbisbee1/DS1000_F2024/raw/main/data/nrc.Rds')
```

---

# Meaning


```r
nrc
```

```
## # A tibble: 13,901 × 2
##    word        sentiment
##    &lt;chr&gt;       &lt;chr&gt;    
##  1 abacus      trust    
##  2 abandon     fear     
##  3 abandon     negative 
##  4 abandon     sadness  
##  5 abandoned   anger    
##  6 abandoned   fear     
##  7 abandoned   negative 
##  8 abandoned   sadness  
##  9 abandonment anger    
## 10 abandonment fear     
## # ℹ 13,891 more rows
```

---

# Sentiment by Pre/Post Presidency

- Measure sentiment by proportion of words

--

- Divide by pre/post presidency

--


```r
word_freq &lt;- tweet_words %&gt;%
  group_by(PostPresident) %&gt;%
  count(word) %&gt;%
  filter(sum(n) &gt;= 5) %&gt;%
   mutate(prop = prop.table(n)) # Faster way of calculating proportions!
```

---

# Sentiment by Pre/Post Presidency

- Attaching sentiment from `nrc`

--

  - `inner_join()`: only keeps words that appear in `nrc`
  

```r
word_freq_sentiment &lt;- word_freq %&gt;%
    inner_join(nrc, by = "word") 
```

---

# Sentiment overall


```r
p &lt;- word_freq_sentiment %&gt;%
  group_by(sentiment) %&gt;%
  top_n(10, n) %&gt;%
  ungroup() %&gt;%
  mutate(word = reorder(word, n)) %&gt;%
  ggplot(aes(y = word, x = n)) +
  facet_wrap(~ sentiment, scales = "free", nrow = 3) + 
  geom_bar(stat = "identity")
```

---

# Sentiment Overall


```r
p
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-17-1.png" style="display: block; margin: auto;" /&gt;

---

# Sentiment overall

- Could also just calculate positive sentiments - negative sentiments

--

  - Want to do this at the tweet level
  
--


```r
tweet_sentiment &lt;- tweet_words %&gt;%
    inner_join(nrc, by = "word") 
  
tweet_sentiment_summary &lt;- tweet_sentiment %&gt;%
  group_by(PostPresident, sentiment) %&gt;%
  count(document,sentiment) %&gt;%
  pivot_wider(names_from = sentiment, 
              values_from = n, 
              values_fill = 0) %&gt;% # same as spread()!
  mutate(sentiment = positive - negative)
```

---

# Sentiment overall


```r
tweet_sentiment_summary
```

```
## # A tibble: 45,592 × 13
## # Groups:   PostPresident [2]
##    PostPresident   document anger anticipation disgust  fear
##    &lt;lgl&gt;              &lt;dbl&gt; &lt;int&gt;        &lt;int&gt;   &lt;int&gt; &lt;int&gt;
##  1 FALSE         1701461182     1            3       1     0
##  2 FALSE         1741160716     1            1       1     0
##  3 FALSE         1924074459     1            1       0     0
##  4 FALSE         2045871770     1            0       0     0
##  5 FALSE         2317112756     1            0       0     1
##  6 FALSE         2346367430     2            1       1     2
##  7 FALSE         2403435685     1            2       1     2
##  8 FALSE         3688564134     1            0       1     1
##  9 FALSE         7677152231     1            1       1     0
## 10 FALSE         8083871612     1            1       1     0
## # ℹ 45,582 more rows
## # ℹ 7 more variables: joy &lt;int&gt;, negative &lt;int&gt;,
## #   positive &lt;int&gt;, sadness &lt;int&gt;, surprise &lt;int&gt;,
## #   trust &lt;int&gt;, sentiment &lt;int&gt;
```

---

# Sentiment by presidency

- Calculate total number of tweets by sentiment

--


```r
tweet_sentiment_summary  %&gt;%
  group_by(PostPresident) %&gt;%
  mutate(ntweet = 1) %&gt;%
  summarize(across(-document, sum)) 
```

```
## # A tibble: 2 × 13
##   PostPresident anger anticipation disgust  fear   joy
##   &lt;lgl&gt;         &lt;int&gt;        &lt;int&gt;   &lt;int&gt; &lt;int&gt; &lt;int&gt;
## 1 FALSE          8138        13333    5356  7999 12440
## 2 TRUE          13892        14095    8933 14051 10973
## # ℹ 7 more variables: negative &lt;int&gt;, positive &lt;int&gt;,
## #   sadness &lt;int&gt;, surprise &lt;int&gt;, trust &lt;int&gt;,
## #   sentiment &lt;int&gt;, ntweet &lt;dbl&gt;
```

---

# Sentiment by presidency

- Univariate distributions!

--


```r
p &lt;- tweet_sentiment_summary %&gt;%
  ggplot(aes(x = sentiment, y = PostPresident)) + 
  geom_boxplot() +
  labs(y= "Trump is president", x = "Sentiment Score: Positive - Negative")
```



---

# Sentiment by presidency

- Univariate distributions!


```r
p
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-22-1.png" style="display: block; margin: auto;" /&gt;

---

# Sentiment by hour

- Univariate distributions

  - Comparing sentiment by hour
  
--


```r
p &lt;- tweet_sentiment %&gt;%
  group_by(PostPresident,Tweeting.hour,sentiment) %&gt;%
  count(document,sentiment) %&gt;%
  pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %&gt;% 
  mutate(sentiment = positive - negative) %&gt;%
  summarize(AvgSentiment = mean(sentiment)) %&gt;%
  ggplot(aes(y = AvgSentiment, x= Tweeting.hour, color=PostPresident)) + 
  geom_point(size = 4) +
  geom_hline(yintercept = 0,linetype = 'dashed') + 
  labs(x = "Tweeting Hour (EST)", y = "Average Tweet Sentiment: Positive - Negative", color = "Is President?")
```

---

# Sentiment by hour

- Comparing sentiment by hour


```r
p
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-24-1.png" style="display: block; margin: auto;" /&gt;


---

# Understanding Trump

- When Trump is coded as "positive" or "negative", what is he saying?

--

- Look at log-odds ratio words, matched to sentiment!


```r
p &lt;- prepost_logodds %&gt;%
  inner_join(nrc, by = "word") %&gt;%
  filter(!sentiment %in% c("positive", "negative")) %&gt;%
  mutate(sentiment = reorder(sentiment, -logodds),
         word = reorder(word, -logodds)) %&gt;%
  group_by(sentiment) %&gt;%
  top_n(10, abs(logodds)) %&gt;%
  ungroup() %&gt;%
  ggplot(aes(y = word, x = logodds, fill = logodds &lt; 0)) +
  facet_wrap(~ sentiment, scales = "free", nrow = 2) +
  geom_bar(stat = "identity") +
  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +
  labs(x = "", y = "Post / Pre log ratio") +
  scale_fill_manual(name = "", labels = c("Post", "Pre"),
                    values = c("red", "lightblue")) + 
  theme(legend.position = 'bottom')
```

---

# Understanding Trump


```r
p
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-26-1.png" style="display: block; margin: auto;" /&gt;

---

# Text as predictors

- Let's say we didn't know when each tweet was written

--

- Could we predict whether it was written during his presidency or not?

--

  - Logit model using **text** as predictors
  
  
---

# Text as Data

- Predict tweets by average of words' log-odds!


```r
toanal &lt;- tweet_words %&gt;%
  select(document,word,PostPresident) %&gt;%
  left_join(prepost_logodds %&gt;% select(word,logodds)) %&gt;% # Link data with log-odds
  group_by(document,PostPresident) %&gt;%
  summarise(logodds = mean(logodds)) %&gt;% # Calculate average log-odds by document
  ungroup()

m &lt;- glm(PostPresident ~ logodds,toanal,family = binomial) # logit regression
```

---

# Text as Data

- Evaluate the performance


```r
require(tidymodels)
forAUC &lt;- toanal %&gt;% # Evaluate model performance
  mutate(preds = predict(m,type = 'response'),
         truth = factor(PostPresident,levels = c('TRUE','FALSE')))

roc_auc(forAUC,'truth','preds')
```

```
## # A tibble: 1 × 3
##   .metric .estimator .estimate
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt;
## 1 roc_auc binary         0.962
```

```r
p &lt;- roc_curve(forAUC,'truth','preds') %&gt;%
  ggplot(aes(x = 1-specificity,y = sensitivity)) + 
  geom_line() + 
  geom_abline(intercept = 0,slope = 1,linetype = 'dashed')
```

---

# Evaluate performance


```r
p
```

&lt;img src="ds1000_lecture_20_slides_files/figure-html/unnamed-chunk-29-1.png" style="display: block; margin: auto;" /&gt;

---

# Evaluate on some sample tweets


```r
raw_tweets &lt;- read_rds('../data/Trumptweets.Rds')
set.seed(20)
toCheck &lt;- raw_tweets %&gt;% slice(sample(1:nrow(.),size = 10))

toCheck %&gt;%
  select(content)
```

```
## # A tibble: 10 × 1
##    content                                                  
##    &lt;chr&gt;                                                    
##  1 "RT @ShannonBream: BREAKING:  POTUS commutes Roger Stone…
##  2 "Congratulations to a future STAR of the Republican Part…
##  3 "@Seanelmi  Thanks Sean."                                
##  4 "\"\"\"@007lLisav: @CNN @realDonaldTrump @CNNPolitics ca…
##  5 "RT @thejtlewis: @realDonaldTrump https://t.co/W7L9kCZK3…
##  6 "RT @TrumpWarRoom: WATCH: @KatrinaPierson explains Joe B…
##  7 "The State Department's 'shadow government' #DrainTheSwa…
##  8 "Sexual pervert Anthony Weiner has zero business holding…
##  9 "TO MY FAVORITE PEOPLE IN THE WORLD! https://t.co/38DbQt…
## 10 "Small businesses will have an ally in the White House w…
```

---

# Evaluate on some sample tweets


```r
toTest &lt;- toCheck %&gt;% left_join(toanal,by = c('id' = 'document')) # Merge the raw text with the log-odds

toTest %&gt;%
  mutate(preds = predict(m,newdata = toTest,type = 'response')) %&gt;%
  select(content,PostPresident,preds) %&gt;%
  mutate(pred_binary = preds &gt; .5) %&gt;%
  filter(PostPresident != pred_binary)
```

```
## # A tibble: 3 × 4
##   content                    PostPresident preds pred_binary
##   &lt;chr&gt;                      &lt;lgl&gt;         &lt;dbl&gt; &lt;lgl&gt;      
## 1 @Seanelmi  Thanks Sean.    FALSE         0.985 TRUE       
## 2 The State Department's 's… FALSE         0.731 TRUE       
## 3 TO MY FAVORITE PEOPLE IN … TRUE          0.316 FALSE
```

```r
# We only make 3 mistakes!
```


---

# Can we do better if we add sentiment?


```r
toanal &lt;- toanal %&gt;%
  left_join(tweet_sentiment_summary) %&gt;%
  drop_na()

m1 &lt;- glm(PostPresident ~ logodds,toanal,family = binomial)
m2 &lt;- glm(PostPresident ~ logodds + sentiment,toanal,family = binomial)
m3 &lt;- glm(PostPresident ~ logodds + anger + anticipation + disgust + fear + joy + sadness + surprise + trust,toanal,family = binomial)

forAUC &lt;- toanal %&gt;%
  mutate(preds1 = predict(m1,type = 'response'),
         preds2 = predict(m2,type = 'response'),
         preds3 = predict(m3,type = 'response'),
         truth = factor(PostPresident,levels = c('TRUE','FALSE')))
```

---

# Can we do better if we add sentiment?


```r
roc_auc(forAUC,'truth','preds1') %&gt;% mutate(model = 'logodds') %&gt;%
  bind_rows(roc_auc(forAUC,'truth','preds2') %&gt;% mutate(model = 'logodds &amp; net sentiment')) %&gt;%
  bind_rows(roc_auc(forAUC,'truth','preds3') %&gt;% mutate(model = 'logodds &amp; detailed sentiment'))
```

```
## # A tibble: 3 × 4
##   .metric .estimator .estimate model                       
##   &lt;chr&gt;   &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;                       
## 1 roc_auc binary         0.966 logodds                     
## 2 roc_auc binary         0.967 logodds &amp; net sentiment     
## 3 roc_auc binary         0.968 logodds &amp; detailed sentiment
```

--

- Not really

---

# Conclusion

- Sentiment can...

--

  - ...help us describe the data (i.e., infer what someone meant)
  
  - ...help us predict the data (RQ: do positive tweets get more likes?)
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="libs/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
